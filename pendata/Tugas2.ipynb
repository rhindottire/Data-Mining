{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier and KNN\n",
    "\n",
    "Outlier adalah data yang memiliki nilai yang jauh berbeda dari sebagian besar data lainnya dalam sebuah dataset, yang dapat disebabkan oleh kesalahan pengukuran, variasi alami, atau faktor eksternal lainnya. Identifikasi outlier penting dalam analisis data karena dapat memengaruhi hasil pemodelan dan pengambilan keputusan. Sementara itu, K-Nearest Neighbors (KNN) adalah algoritma pembelajaran mesin berbasis instance yang digunakan untuk klasifikasi dan regresi dengan menentukan kelas atau nilai suatu data berdasarkan mayoritas dari k tetangga terdekatnya. KNN sangat bergantung pada metrik jarak, seperti Euclidean Distance, dan dapat dipengaruhi oleh outlier, karena titik data yang ekstrem dapat mengganggu perhitungan kedekatan dan hasil prediksi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection\n",
    "Outlier adalah titik data yang berbeda secara signifikan dari sebagian besar data. Mereka mungkin timbul karena:\n",
    "\n",
    "- **Data entry errors**: Nilai yang dicatat salah.\n",
    "- **Measurement errors**: Sensor atau instrumen rusak.\n",
    "- **Natural variability**: Pengamatan yang ekstrim namun valid (pendapatan seorang miliarder dalam kumpulan data pendapatan rata-rata).\n",
    "\n",
    "### Why is Outlier Detection Important?\n",
    "- Outliers dapat mendistorsi analisis statistik (mean, deviasi standar).\n",
    "- Hal ini dapat berdampak negatif terhadap performa model pembelajaran mesin.\n",
    "- Dalam beberapa kasus, outlier mungkin mewakili informasi penting (deteksi penipuan).\n",
    "\n",
    "### Methods for Outlier Detection\n",
    "1. **Statistical Methods**:\n",
    "   - _Z-Score_: Mengukur berapa banyak standar deviasi suatu titik data dari mean. Titik data dengan skor Z lebih besar dari 3 atau kurang dari -3 sering kali dianggap outlier.\n",
    "   - _IQR (Interquartile Range)_: Mengidentifikasi outlier sebagai titik data di bawah Q1 - 1,5IQR atau di atas Q3 + 1,5IQR, dengan Q1 dan Q3 masing-masing adalah kuartil pertama dan ketiga.\n",
    "2. **Visual Methods**:\n",
    "   - _Box Plots_: Representasi grafis dari distribusi data. Outliers ditampilkan sebagai titik di luar \"whiskers\" plot kotak.\n",
    "   - _Scatter Plots_: Berguna untuk mengidentifikasi outlier dalam data bivariat (dua variabel).\n",
    "3. **Machine Learning Methods**:\n",
    "   - _Clustering_: Outliers mungkin muncul sebagai titik data yang bukan milik cluster mana pun.\n",
    "   - _Isolation Forest_: Algoritme yang dirancang khusus untuk mendeteksi outlier dengan mengisolasi titik data.\n",
    "   - _DBSCAN (Density-Based Spatial Clustering of Applications with Noise)_: Mengidentifikasi outlier sebagai titik di wilayah dengan kepadatan rendah.\n",
    "   - **KNN (K-Nearest Neighbors)**: Menggunakan jarak ke tetangga terdekat untuk mengidentifikasi outlier.\n",
    "4. **Domain-Specific Methods**:\n",
    "   - Gunakan pengetahuan domain untuk mengidentifikasi outlier. Misalnya, dalam layanan kesehatan, usia pasien 150 tahun merupakan hal yang berbeda.\n",
    "\n",
    "### Handling Outliers\n",
    "Setelah outlier terdeteksi, Anda perlu memutuskan cara menanganinya:\n",
    "\n",
    "- **Remove**: Jika outlier disebabkan oleh kesalahan atau **noise**.\n",
    "- **Transform**: Menerapkan transformasi (transformasi log) untuk mengurangi dampak outlier.\n",
    "- **Cap/Floor**: Ganti outlier dengan nilai ambang batas maksimum atau minimum.\n",
    "- **Keep**: Jika outlier tersebut valid dan bermakna (kasus penipuan).\n",
    "\n",
    "### Summary of Outlier Detection in Data Understanding\n",
    "- Outlier adalah titik data yang menyimpang secara signifikan dari data lainnya.\n",
    "- Mendeteksi dan menangani outlier sangat penting untuk memastikan kualitas data dan analisis yang akurat.\n",
    "- Metode untuk mendeteksi outlier mencakup teknik statistik (Z-score, IQR), metode visual (box plots, scatter plots), dan algoritma pembelajaran mesin (Isolation Forest, DBSCAN).\n",
    "- Outliers harus dievaluasi secara hati-hati untuk menentukan apakah itu kesalahan atau pengamatan yang bermakna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (KNN) for Outlier Detection\n",
    "KNN adalah algoritma sederhana namun efektif yang dapat digunakan untuk classification dan outlier detection. Ide di balik KNN untuk outlier detection didasarkan pada asumsi bahwa outlier adalah titik data yang letaknya jauh dari tetangga terdekatnya.\n",
    "\n",
    "### How KNN Works for Outlier Detection?\n",
    "1. **Step 1: Choose a Value for K**\n",
    "   - Pilih jumlah tetangga (K) yang akan dipertimbangkan. Misalnya, K=3 berarti algoritma akan melihat 3 tetangga terdekat untuk setiap titik data.\n",
    "2. **Step 2: Calculate Distances**\n",
    "   - Hitung jarak (**Euclidean distance**, Manhattan distance, dan Minkowski distance) antara setiap titik data dan K tetangga terdekatnya.\n",
    "3. **Step 3: Identify Outliers**\n",
    "   - Titik data dengan jarak yang lebih jauh ke tetangganya dianggap outlier. Misalnya, jika jarak rata-rata ke K tetangga terdekat jauh lebih besar dibandingkan sebagian besar data, maka titik tersebut ditandai sebagai outlier.\n",
    "\n",
    "#### What is Euclidean Distance?\n",
    "Euclidean distance adalah salah satu metrik jarak yang paling umum digunakan dalam ilmu data dan pembelajaran mesin. Ini mengukur jarak garis lurus antara dua titik dalam ruang multidimensi. Ini berasal dari teorema Pythagoras dan digunakan secara luas karena kesederhanaan dan interpretasi intuitifnya.\n",
    "\n",
    "#### Formula\n",
    "\n",
    "### **Dataset Baru**\n",
    "Misalkan kita memiliki 10 titik data sebagai berikut:\n",
    "\n",
    "| Class | x  | y  |\n",
    "|-------|----|----|\n",
    "| A     | 2  | 3  |\n",
    "| A     | 3  | 7  |\n",
    "| A     | 5  | 5  |\n",
    "| B     | 8  | 2  |\n",
    "| B     | 6  | 3  |\n",
    "| B     | 7  | 4  |\n",
    "| A     | 4  | 6  |\n",
    "| A     | 3  | 5  |\n",
    "| B     | 10 | 7  |\n",
    "| ?     | 4  | 4  |\n",
    "\n",
    "### **1. Menghitung Jarak dengan Euclidean Distance**\n",
    "Rumus Euclidean Distance:\n",
    "\n",
    "$$\n",
    "d = \\sqrt{(x - x_{q})^2 + (y - y_{q})^2}\n",
    "$$\n",
    "\n",
    "di mana \\((x_{q}, y_{q})\\) adalah koordinat titik uji (4,4).\n",
    "\n",
    "Lakukan perhitungan untuk masing-masing titik:\n",
    "\n",
    "1. **Titik (2,3), Class A**  \n",
    "   $$\n",
    "   d = \\sqrt{(2 - 4)^2 + (3 - 4)^2} = \\sqrt{(-2)^2 + (-1)^2} = \\sqrt{4 + 1} = \\sqrt{5} \\approx 2.236\n",
    "   $$\n",
    "\n",
    "2. **Titik (3,7), Class A**  \n",
    "   $$\n",
    "   d = \\sqrt{(3 - 4)^2 + (7 - 4)^2} = \\sqrt{(-1)^2 + 3^2} = \\sqrt{1 + 9} = \\sqrt{10} \\approx 3.162\n",
    "   $$\n",
    "\n",
    "3. **Titik (5,5), Class A**  \n",
    "   $$\n",
    "   d = \\sqrt{(5 - 4)^2 + (5 - 4)^2} = \\sqrt{1^2 + 1^2} = \\sqrt{1 + 1} = \\sqrt{2} \\approx 1.414\n",
    "   $$\n",
    "\n",
    "4. **Titik (8,2), Class B**  \n",
    "   $$\n",
    "   d = \\sqrt{(8 - 4)^2 + (2 - 4)^2} = \\sqrt{4^2 + (-2)^2} = \\sqrt{16 + 4} = \\sqrt{20} \\approx 4.472\n",
    "   $$\n",
    "\n",
    "5. **Titik (6,3), Class B**  \n",
    "   $$\n",
    "   d = \\sqrt{(6 - 4)^2 + (3 - 4)^2} = \\sqrt{2^2 + (-1)^2} = \\sqrt{4 + 1} = \\sqrt{5} \\approx 2.236\n",
    "   $$\n",
    "\n",
    "6. **Titik (7,4), Class B**  \n",
    "   $$\n",
    "   d = \\sqrt{(7 - 4)^2 + (4 - 4)^2} = \\sqrt{3^2 + 0^2} = \\sqrt{9} = 3.000\n",
    "   $$\n",
    "\n",
    "7. **Titik (4,6), Class A**  \n",
    "   $$\n",
    "   d = \\sqrt{(4 - 4)^2 + (6 - 4)^2} = \\sqrt{0 + 2^2} = \\sqrt{4} = 2.000\n",
    "   $$\n",
    "\n",
    "8. **Titik (3,5), Class A**  \n",
    "   $$\n",
    "   d = \\sqrt{(3 - 4)^2 + (5 - 4)^2} = \\sqrt{(-1)^2 + 1^2} = \\sqrt{1 + 1} = \\sqrt{2} \\approx 1.414\n",
    "   $$\n",
    "\n",
    "9. **Titik (10,7), Class B**  \n",
    "   $$\n",
    "   d = \\sqrt{(10 - 4)^2 + (7 - 4)^2} = \\sqrt{6^2 + 3^2} = \\sqrt{36 + 9} = \\sqrt{45} \\approx 6.708\n",
    "   $$\n",
    "\n",
    "### **2. Merangking Data Secara Ascending (Kecil â†’ Besar)**\n",
    "\n",
    "| Rank | Jarak  | Class | Keterangan         |\n",
    "|------|--------|-------|--------------------|\n",
    "| 1    | 1.414  | A     | (Titik (5,5))      |\n",
    "| 2    | 1.414  | A     | (Titik (3,5))      |\n",
    "| 3    | 2.000  | A     | (Titik (4,6))      |\n",
    "| 4    | 2.236  | A     | (Titik (2,3))      |\n",
    "| 5    | 2.236  | B     | (Titik (6,3))      |\n",
    "| 6    | 3.000  | B     | (Titik (7,4))      |\n",
    "| 7    | 3.162  | A     | (Titik (3,7))      |\n",
    "| 8    | 4.472  | B     | (Titik (8,2))      |\n",
    "| 9    | 6.708  | B     | (Titik (10,7))     |\n",
    "\n",
    "\n",
    "\n",
    "### Advantages of KNN for Outlier Detection\n",
    "- **Simple and Intuitive**: Mudah dipahami dan diterapkan.\n",
    "- **No Assumptions About Data Distribution**: Berfungsi dengan baik untuk data dengan struktur yang kompleks.\n",
    "- **Flexible**: Dapat digunakan untuk dataset kecil dan besar.\n",
    "\n",
    "### Limitations of KNN for Outlier Detection:\n",
    "- **Computationally Expensive**: Menghitung jarak untuk kumpulan data besar bisa jadi lambat.\n",
    "- **Sensitive to the Choice of K**: Hasilnya sangat bergantung pada nilai K.\n",
    "- **Requires Scaling**: Fitur harus dinormalisasi atau distandarisasi untuk memastikan jarak bermakna.\n",
    "\n",
    "### Summary of KNN for Outlier Detection\n",
    "- KNN adalah metode berbasis jarak yang mengidentifikasi outlier sebagai titik data yang jauh dari tetangga terdekatnya.\n",
    "- Ini sederhana, fleksibel, dan berfungsi dengan baik untuk kumpulan data dengan struktur kompleks.\n",
    "- Namun, hal ini dapat menjadi mahal secara komputasi dan sensitif terhadap pilihan K.\n",
    "- KNN adalah alat yang berharga dalam fase Pemahaman Data untuk mengidentifikasi dan menangani outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation Requirements\n",
    "\n",
    "1. `pymysql`\n",
    "   * Tujuan: Konektor database MySQL untuk Python.\n",
    "   * Use Case: Sambungkan ke database MySQL, jalankan query SQL, dan ambil hasilnya.\n",
    "2. `psycopg2-binary`\n",
    "   * Tujuan: Adaptor database PostgreSQL untuk Python.\n",
    "   * Use Case: Berinteraksi dengan database PostgreSQL.\n",
    "3. `sqlalchemy`\n",
    "   * Tujuan: Toolkit SQL dan pustaka Object-Relational Mapping (ORM).\n",
    "   * Use Case:\n",
    "      - Tulis kode database-agnostik (berfungsi dengan MySQL, PostgreSQL, SQLite, dll.).\n",
    "      - Tentukan tabel dan hubungan menggunakan kelas Python.\n",
    "      - Gunakan mesin SQLAlchemy untuk terhubung ke database (sering dipasangkan dengan pandas).\n",
    "4. `pandas`\n",
    "   * Tujuan: Perpustakaan manipulasi dan analisis data.\n",
    "   * Use Case:\n",
    "      - Memuat data dari database CSV/Excel/SQL ke objek DataFrame.\n",
    "      - Bersihkan, ubah, dan analisis data terstruktur.\n",
    "5. `python-dotenv`\n",
    "   * Tujuan: Memuat variabel lingkungan dari file .env.\n",
    "   * Use Case: Menyimpan kredensial database, kunci API, atau rahasia lainnya dengan aman.\n",
    "6. `matplotlib`\n",
    "   * Tujuan: Perpustakaan plot dan visualisasi.\n",
    "   * Use Case: Membuat grafik (diagram garis, histogram, plot sebar) untuk menjelajahi dan menyajikan data.\n",
    "7. `scikit-learn`\n",
    "   * Tujuan: Pustaka machine learning untuk Python.\n",
    "   * Use Case:\n",
    "      - Menerapkan algoritma machine learning (klasifikasi, regresi, clustering, dll.).\n",
    "      - Mengekstraksi fitur, melakukan validasi silang, dan evaluasi model.\n",
    "      - Menggunakan pipeline untuk preprocessing dan pelatihan model.\n",
    "\n",
    "### Why These Packages Together?\n",
    "1. Terhubung ke database (MySQL/PostgreSQL) melalui pymysql/psycopg2.\n",
    "2. Menggunakan sqlalchemy untuk interaksi database yang fleksibel.\n",
    "3. Menggunakan pandas untuk manipulasi data.\n",
    "4. Mengamankan kredensial dengan python-dotenv.\n",
    "5. Memvisualisasikan hasil dengan matplotlib.\n",
    "6. Menerapkan teknik machine learning dengan scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymysql in d:\\github\\lecture-projects\\data-mining\\.venv\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: psycopg2-binary in d:\\github\\lecture-projects\\data-mining\\.venv\\lib\\site-packages (2.9.10)\n",
      "Requirement already satisfied: sqlalchemy in d:\\github\\lecture-projects\\data-mining\\.venv\\lib\\site-packages (2.0.38)\n",
      "Requirement already satisfied: pandas in d:\\github\\lecture-projects\\data-mining\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: python-dotenv in d:\\github\\lecture-projects\\data-mining\\.venv\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: matplotlib in d:\\github\\lecture-projects\\data-mining\\.venv\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: scikit-learn in d:\\github\\lecture-projects\\data-mining\\.venv\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\github\\lecture-projects\\data-mining\\.venv\\lib\\site-packages (from sqlalchemy) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in d:\\github\\lecture-projects\\data-mining\\.venv\\lib\\site-packages (from sqlalchemy) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in d:\\github\\lecture-projects\\data-mining\\.venv\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\github\\lecture-projects\\data-mining\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\github\\lecture-projects\\data-mining\\.venv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\github\\lecture-projects\\data-mining\\.venv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\github\\lecture-projects\\data-mining\\.venv\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\github\\lecture-projects\\data-mining\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\github\\lecture-projects\\data-mining\\.venv\\lib\\site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\github\\lecture-projects\\data-mining\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\github\\lecture-projects\\data-mining\\.venv\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in d:\\github\\lecture-projects\\data-mining\\.venv\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\github\\lecture-projects\\data-mining\\.venv\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\github\\lecture-projects\\data-mining\\.venv\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\github\\lecture-projects\\data-mining\\.venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\github\\lecture-projects\\data-mining\\.venv\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\github\\lecture-projects\\data-mining\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pymysql psycopg2-binary sqlalchemy pandas python-dotenv matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import matplotlib.pyplot as plt\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id           class  petal length  petal width  sepal length  sepal width\n",
      "0      1     Iris-setosa          86.4         70.0          20.1         30.5\n",
      "1      2     Iris-setosa           1.4          0.2           4.9          3.0\n",
      "2      3     Iris-setosa           1.3          0.2           4.8          3.2\n",
      "3      4     Iris-setosa           1.5          0.2           4.6          3.1\n",
      "4      5     Iris-setosa           1.4          0.2           5.0          3.6\n",
      "..   ...             ...           ...          ...           ...          ...\n",
      "145  146  Iris-virginica           5.2          2.3           6.7          3.0\n",
      "146  147  Iris-virginica           5.0          1.9           6.3          2.5\n",
      "147  148  Iris-virginica           5.2          2.0           6.5          3.0\n",
      "148  149  Iris-virginica           5.4          2.3           6.2          3.4\n",
      "149  150  Iris-virginica           5.1          1.8           5.9          3.0\n",
      "\n",
      "[150 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  mysql_url = os.getenv(\"MYSQL_URL\")\n",
    "  postgres_url = os.getenv(\"POSTGRES_URL\")\n",
    "  mysql_engine = create_engine(mysql_url)\n",
    "  postgres_engine = create_engine(postgres_url)\n",
    "  df_mysql = pd.read_sql(\"SELECT * FROM iris_mysql\",mysql_engine)\n",
    "  df_postgres = pd.read_sql(\"SELECT * FROM iris_postgre ORDER BY id\",postgres_engine)\n",
    "\n",
    "  df_postgres = df_postgres.drop(columns=[\"class\"])\n",
    "  df_iris = df_mysql.merge(df_postgres, on=\"id\")\n",
    "  df_iris.to_csv(\"iris_combined.csv\", index=False)\n",
    "  print(df_iris)\n",
    "\n",
    "except Exception as e:\n",
    "  print(f\"Error message: {e}\")\n",
    "\n",
    "finally:\n",
    "  mysql_engine.dispose()\n",
    "  postgres_engine.dispose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
